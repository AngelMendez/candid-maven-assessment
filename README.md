# End-to-End Lead Routing System

This project is a robust, scalable, and fully asynchronous lead routing system built entirely on the Supabase platform. It's designed to capture user submissions from a web form, validate them, and intelligently route them to different partner APIs based on a dynamic, database-driven rules engine.

## Core Features ‚ú®

- **Asynchronous Processing**: The system uses a queue-based architecture to provide instant feedback to the user while processing leads reliably in the background.

- **Dynamic Routing Engine**: Routing rules are stored in the database, allowing non-technical teams to update business logic without deploying new code.

- **Automated Retries & Error Handling**: A worker function automatically retries failed API calls and isolates persistently failing jobs in a dead-letter queue.

- **Real-time Monitoring**: A live dashboard built within Supabase provides key performance metrics like submissions per partner and failure rates.

- **Type-Safe Development**: The project leverages TypeScript end-to-end, with types automatically generated from the database schema for maximum reliability.

## Architecture üèóÔ∏è

The system follows an asynchronous, queue-based architecture to decouple lead ingestion from lead processing.

1. **Ingestion**: A user submits a form on a static frontend (GitHub Pages). The form makes a POST request to the `submit-lead` Edge Function.

2. **Enqueue**: The `submit-lead` function validates the data and immediately inserts it into the `lead_processing_queue` table with a `pending` status. It then responds to the user with a `202 Accepted`.

3. **Trigger**: A Supabase Database Webhook detects the `INSERT` event on the queue table and automatically triggers the `process-lead-worker` Edge Function.

4. **Processing**: The `process-lead-worker` function fetches the job, determines the correct partner API using rules from the `routing_rules` table, calls the external API, and handles any necessary retries.

5. **Logging**: The final result of the job (`SUCCESS` or `FAILED`) is recorded in the `submission_logs` table, which feeds the monitoring dashboard.

## Tech Stack üõ†Ô∏è

- **Backend**: Supabase Edge Functions (Deno, TypeScript)
- **Database**: Supabase/PostgreSQL
- **Frontend**: HTML, Vanilla JavaScript (Deployed on GitHub Pages)
- **Validation**: Zod
- **Testing**: Deno Native Test Runner

## Database Schema üìú

The system relies on four core tables:

```sql
-- Stores validated lead data (can be populated after processing for historical reference)
CREATE TABLE public.leads ( ... );

-- Acts as the job queue for asynchronous processing
CREATE TABLE public.lead_processing_queue ( ... );

-- Stores the dynamic rules for the routing engine
CREATE TABLE public.routing_rules ( ... );

-- Records the final outcome of every submission for analytics
CREATE TABLE public.submission_logs ( ... );

-- A SQL View to power the monitoring dashboard
CREATE VIEW public.daily_partner_performance AS ...;
```

## Local Development Setup üöÄ

### Install Supabase CLI

```bash
npm i -g supabase
```

### Start Supabase Services

From the project root, run:

```bash
supabase start
```

### Serve Functions

In a new terminal window, serve the Edge Functions to enable live reloading:

```bash
supabase functions serve
```

### View Logs

In a third terminal window, tail the logs to debug in real-time:

```bash
supabase logs --functions
```

### Test Endpoints

Use a tool like cURL or Postman to send requests to the local function URLs (e.g., `http://127.0.0.1:54321/functions/v1/submit-lead`).

## Use of AI in Development ü§ñ

Artificial intelligence was used as a productivity accelerator throughout the development process, primarily for generating boilerplate code and test cases. All AI-generated output was manually reviewed, validated, and refactored to fit the project's specific architectural and security needs.

**Tools Used**: Google Gemini & Claude Code

### Prompts & Use Cases

- **Schema Generation**: "Given this JSON object `{ "name": "...", "email": "..." }`, generate a Zod validation schema in TypeScript." This sped up the initial setup of data validation.

- **Boilerplate Code**: "Create a basic Supabase Edge Function using Deno that accepts a POST request, parses the JSON body, and returns a success message." This provided the foundational structure for our functions.

- **Test Case Generation**: "Here is a TypeScript function that implements routing logic. Generate a comprehensive set of unit tests using Deno's native test runner, covering all explicit rules and at least three edge cases." This ensured robust test coverage for the critical routing logic.

- **SQL Query Generation**: "Write a PostgreSQL query that groups submission logs by day and partner, and calculates the total submissions and failure rate percentage." This helped build the SQL VIEW for the monitoring dashboard quickly.

### Validation Process

Manual validation was critical. For example, AI-generated Zod schemas were checked to ensure they enforced the correct constraints (e.g., `min(1)` for required fields). Similarly, generated code was refactored to include proper error handling, environment variable usage, and security headers (like CORS). AI provided the first draft, but the final, production-ready code was the result of human oversight.
